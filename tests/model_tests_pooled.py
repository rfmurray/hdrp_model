# model_tests.py  Test HDRP model model predictions

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from hdrp import srgb, srgbinv, TonemapCube, cubetag

# choose whether to test results from Unity project render_random with
# Lambertian or unlit material
testLambertian = True

# choose cube files
cubelist = ['cube/linear_max1.cube', 'cube/square_max1.cube', 'cube/square_root_max1.cube']
cuben = len(cubelist)

# load tonemaps
tonemap = [TonemapCube(f) for f in cubelist]

# assign knot points
# delta functions
u_knot = [0, 1e-09, 0.00026059, 0.00310441, 0.00730495, 0.0128806, 0.0205608, 0.0306122, 0.0446793, 0.0639257, 0.0905573, 0.124511, 0.171195, 0.235383, 0.323638, 0.440577, 0.59383, 0.816481, 1.1115, 1.49813, 2.03945, 2.77635, 3.77952, 5.09423, 6.93491, 9.44068, 12.7246, 17.3224, 23.3479, 31.7842, 43.2686, 58.9028]
# model optimization
u_knot = [0, 1e-09, 9.82132e-09, 0.00284923, 0.00719612, 0.0127425, 0.0205489, 0.0309998, 0.0450249, 0.0641519, 0.0901781, 0.12527, 0.172976, 0.237221, 0.325983, 0.44253, 0.604314, 0.821369, 1.10384, 1.49459, 2.03212, 2.75649, 3.73814, 5.08289, 6.86428, 9.34713, 12.6195, 17.1796, 23.2405, 31.4807, 42.7522, 57.6644]
for t in tonemap:
    t.u_knot = np.array(u_knot)

# load data generated by Unity project render_random
df = []
for i, cubefile in enumerate(cubelist):
    fname = f'data/data_L{int(testLambertian)}_T1{cubetag(cubefile)}.txt'
    df2 = pd.read_csv(fname)
    df2['cubenum'] = i
    df.append(df2)
df = pd.concat(df)

# discard samples that may be maxed out
k = (df[['v_r', 'v_g', 'v_b']] <= 0.99).all(axis=1)
df = df[k]

# discard samples with low material color coordinates
k = (df[['m_r', 'm_g', 'm_b']] >= 0.20).all(axis=1)
df = df[k]

# create numpy arrays for model parameters
e = df['e'].to_numpy().reshape((-1, 1))  # exposure
m = df[['m_r', 'm_g', 'm_b']].to_numpy()  # material color
d = df[['d_r', 'd_g', 'd_b']].to_numpy()  # directional light color
a = df[['a_r', 'a_g', 'a_b']].to_numpy()  # ambient light color
v = df[['v_r', 'v_g', 'v_b']].to_numpy()  # post-processed color
i_d = df['i_d'].to_numpy().reshape((-1, 1))  # directional light intensity
i_a = df['i_a'].to_numpy().reshape((-1, 1))  # directional light intensity
l = df[['l_x', 'l_y', 'l_z']].to_numpy()  # lighting direction
n = df[['n_x', 'n_y', 'n_z']].to_numpy()  # plane surface normal
costheta = (l * n).sum(axis=1, keepdims=True)  # cosine of angle between lighting direction and plane surface normal
cubenum = df['cubenum']  # number of cube file used

# apply Lambertian or unlit rendering model
if testLambertian:
    c = 0.822
    u_hat = c * srgb(m) * (i_d * srgb(d) * costheta.clip(min=0) / np.pi + i_a * a) / (2 ** e)
else:
    u_hat = srgb(m)

# initialize plot for results
fig = plt.figure(figsize=(13, 5.5))
ax1 = fig.add_subplot(1, 2, 1)
ax2 = fig.add_subplot(1, 2, 2)

# step through cube files
handle1 = 3 * [None, ]
handle2 = 3 * [None, ]
for i in range(cuben):

    # get data for this cube file, and apply post-processing
    k = cubenum == i
    t_hat = tonemap[i].apply(u_hat[k, :])
    v_hat = srgbinv(t_hat)
    vv = v[k, :]

    # plot predicted post-processed color coordinates v_k against actual v_k
    kk = np.random.randint(low=0, high=v_hat.shape[0], size=20)
    for j in range(3):
        handle1[i] = ax1.scatter(vv[kk, j], v_hat[kk, j], color='rgb'[i])

    # plot prediction error in v_k against actual v_k
    kk = np.random.randint(low=0, high=v_hat.shape[0], size=50)
    for j in range(3):
        handle2[i] = ax2.scatter(vv[kk, j], v_hat[kk, j] - vv[kk, j], color='rgb'[i])

# format left panel
xylim = np.array([0, 1.1])
ax1.plot(xylim, xylim, 'k-')
ax1.legend(handle1, ['linear', 'square', 'square root'], frameon=False, loc='upper left')
ax1.set_xlabel('actual $v_k$', fontsize=18)
ax1.set_ylabel('predicted $v_k$', fontsize=18)
ax1.set_xlim(xylim)
ax1.set_ylim(xylim)
ax1.set_aspect(1)
ax1.text(0.85, 0.1, '(a)', fontsize=24)

# format right panel
xlim = np.array([0, 1])
ax2.legend(handle2, ['linear', 'square', 'square root'], frameon=False, loc='upper left')
ax2.plot(xlim, (-1 / 255) * np.ones(2), 'k-')
ax2.plot(xlim, (1 / 255) * np.ones(2), 'k-')
ax2.set_xlabel('actual $v_k$', fontsize=18)
ax2.set_ylabel('prediction error', fontsize=18)
ax2.set_xlim(xlim)
ax2.set_ylim((-0.02, 0.02))
ax2.set_aspect(1. / ax2.get_data_ratio())
ax2.text(0.85, -0.012, '(b)', fontsize=24)

plt.savefig(f'figures/model_tests_pooled_L{int(testLambertian)}.pdf', bbox_inches='tight')
plt.show()
