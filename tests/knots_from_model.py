# knots_from_model.py  Estimate knot points by optimizing HDRP model predictions

import os
import numpy as np
import pandas as pd
from scipy import optimize
import matplotlib.pyplot as plt
from hdrp import srgb, srgbinv, TonemapCube, cubetag

# choose whether to test results from Unity project render_random with
# Lambertian or unlit material
testLambertian = True

# choose cube files
cubelist = ['cube/identity.cube', 'cube/square.cube', 'cube/square_root.cube']
tonemap = [TonemapCube(f) for f in cubelist]
cuben = len(cubelist)

# load data generated by Unity project render_random
df = []
for i, cubefile in enumerate(cubelist):
    fname = f'data/data_L{int(testLambertian)}_T1{cubetag(cubefile)}.txt'
    df2 = pd.read_csv(fname)
    df2['cubenum'] = i
    df.append(df2)
df = pd.concat(df)

# discard samples that may be maxed out
k = (df[['v_r','v_g','v_b']] <= 0.99).all(axis=1)
df = df[k]

# discard samples with low material color coordinates
k = (df[['m_r','m_g','m_b']] >= 0.20).all(axis=1)
df = df[k]

# create numpy arrays for model parameters
e = df['e'].to_numpy().reshape((-1,1))       # exposure
m = df[['m_r','m_g','m_b']].to_numpy()       # material color
d = df[['d_r','d_g','d_b']].to_numpy()       # directional light color
a = df[['a_r','a_g','a_b']].to_numpy()       # ambient light color
v = df[['v_r','v_g','v_b']].to_numpy()       # post-processed color
i_d = df['i_d'].to_numpy().reshape((-1,1))   # directional light intensity
i_a = df['i_a'].to_numpy().reshape((-1,1))   # directional light intensity
l = df[['l_x','l_y','l_z']].to_numpy()       # lighting direction
n = df[['n_x','n_y','n_z']].to_numpy()       # plane surface normal
costheta = (l*n).sum(axis=1, keepdims=True)  # cosine of angle between lighting direction and plane surface normal
cubenum = df['cubenum']                      # number of cube file used

# apply Lambertian or unlit rendering model
if testLambertian:
    c = 0.822
    u_hat = c * srgb(m) * ( i_d * srgb(d) * costheta.clip(min=0) / np.pi + i_a * a ) / (2**e)
else:
    u_hat = srgb(m)

i1 = 2
i2 = 17

# constraint: each knot point is less than the next knot point
nknot = (i2-i1)+1
A1 = np.identity(nknot) + np.diag((nknot-1)*(-1,), 1)
A1 = A1[:-1,:]
lb1 = np.full((A1.shape[0],), -np.inf)
ub1 = np.zeros((A1.shape[0],))

# constraint: first knot point being varied is greater than its next lower neighbour
A2 = np.zeros((1, nknot))
A2[0,0] = 1
lb2 = np.array((tonemap[0].u_knot[i1-1],))
ub2 = np.array((np.inf,))

# constraint: last knot point being varied is greater than its next higher neighbour
A3 = np.zeros((1, nknot))
A3[0,-1] = 1
lb3 = np.array((-np.inf,))
if i2==31:
    ub3 = np.array((60,))
else:
    ub3 = np.array((tonemap[0].u_knot[i2+1],))

# combine constraints
A = np.vstack((A1, A2, A3))
lb = np.concatenate((lb1, lb2, lb3))
ub = np.concatenate((ub1, ub2, ub3))
cons = optimize.LinearConstraint(A=A, lb=lb, ub=ub)

# define objective function
def errfn(param):

    # check that constraints are satisifed
    # (the tonemapping function throws an exception if they're not)
    x = A @ param
    if not ((lb <= x) & (x <= ub)).all():
        return np.inf
    
    # find prediction error
    err = 0
    for i in range(cuben):
        tonemap[i].u_knot[i1:i2+1] = param
        k = cubenum == i
        t_hat = tonemap[i].apply(u_hat[k,:])
        v_hat = srgbinv(t_hat)
        err += ((v[k,:]-v_hat)**2).sum()
    
    return err

# find knot points that optimize prediction accuracy
pinit = tonemap[0].u_knot[i1:i2+1]
r = optimize.minimize(errfn, pinit, constraints=cons)
print(r)

# assign new points to tonemapping objects, and print knot points
for t in tonemap:
    t.u_knot[i1:i2+1] = r.x
print(np.array2string(tonemap[0].u_knot, formatter={'float' : lambda u : f'{u:.6g}'}, separator=', ', max_line_width=np.inf))

# initialize plot for results
fig = plt.figure(figsize=(13,5.5))
ax1 = fig.add_subplot(1,2,1)
ax2 = fig.add_subplot(1,2,2)

# step through cube files
for i in range(len(cubelist)):
    
    # get data for this cube file, and apply post-processing
    k = cubenum == i
    t_hat = tonemap[i].apply(u_hat[k,:])
    v_hat = srgbinv(t_hat)
    vv = v[k,:]
    
    # plot predicted post-processed color coordinates v_k against actual v_k
    kk = np.random.randint(low=0, high=v_hat.shape[0], size=50)
    for j in range(3):
        ax1.scatter(vv[kk,j], v_hat[kk,j], color='rgb'[i])
    
    # plot prediction error in v_k against actual v_k
    for j in range(3):
        ax2.scatter(vv[kk,j], v_hat[kk,j] - vv[kk,j], color='rgb'[j])

# format left panel
xylim = np.array([0,1.1])
ax1.plot(xylim, xylim, 'k-')
ax1.legend(['red channel','green channel','blue channel'], frameon=False, loc='upper left')
ax1.set_xlabel('actual $v_k$', fontsize=18)
ax1.set_ylabel('predicted $v_k$', fontsize=18)
ax1.set_xlim(xylim)
ax1.set_ylim(xylim)
ax1.set_aspect(1)
ax1.text(0.85,0.1,'(a)',fontsize=24)

# format right panel
xlim = np.array([0,1])
ax2.legend(['red channel','green channel','blue channel'], frameon=False, loc='lower right')
ax2.plot(xlim,(-1/255)*np.ones(2),'k-')
ax2.plot(xlim,(1/255)*np.ones(2),'k-')
ax2.set_xlabel('actual $v_k$', fontsize=18)
ax2.set_ylabel('prediction error', fontsize=18)
ax2.set_xlim(xlim)
ax2.set_ylim((-0.02,0.02))
ax2.set_aspect(1./ax2.get_data_ratio())
ax2.text(0.85,-0.012,'(b)',fontsize=24)

plt.savefig(f'figures/knots_from_model.pdf', bbox_inches='tight')
plt.show()
