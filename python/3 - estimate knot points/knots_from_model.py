# knots_from_model.py  Estimate knot points by optimizing HDRP model predictions

import os
import numpy as np
import pandas as pd
from scipy import optimize
import matplotlib.pyplot as plt
from hdrp import srgb, srgbinv, TonemapCube, cubetag

# choose whether to test results from Unity project render_random with Lambertian or unlit material
testLambertian = True

# choose cube files
cubelists = [['cube/linear_max58.cube', 'cube/square_max58.cube', 'cube/square_root_max58.cube'],
             ['cube/linear_max1.cube', 'cube/square_max1.cube', 'cube/square_root_max1.cube']]

# we'll make two passes; in the first pass, we'll optimize all knot points,
# and in the second pass, we'll optimize just knot points for u_k in the range [0, 1]
for passnum in range(2):

    # get cube filenames for this pass, and load tonemaps from cube files
    cubelist = cubelists[passnum]
    tonemap = [TonemapCube(f) for f in cubelist]
    cuben = len(cubelist)
    
    # load data generated by Unity project render_random
    df = []
    for i, cubefile in enumerate(cubelist):
        fname = f'data/tonemap_on_fit/data_L{int(testLambertian)}_T1{cubetag(cubefile)}.txt'
        df2 = pd.read_csv(fname)
        df2['cubenum'] = i
        df.append(df2)
    df = pd.concat(df)
    
    # discard samples that may be maxed out
    k = (df[['v_r','v_g','v_b']] <= 0.99).all(axis=1)
    df = df[k]
    
    # discard samples with low material color coordinates
    k = (df[['m_r','m_g','m_b']] >= 0.20).all(axis=1)
    df = df[k]
    
    # create numpy arrays for model parameters
    e = df['e'].to_numpy().reshape((-1,1))       # exposure
    m = df[['m_r','m_g','m_b']].to_numpy()       # material color
    d = df[['d_r','d_g','d_b']].to_numpy()       # directional light color
    a = df[['a_r','a_g','a_b']].to_numpy()       # ambient light color
    v = df[['v_r','v_g','v_b']].to_numpy()       # post-processed color
    i_d = df['i_d'].to_numpy().reshape((-1,1))   # directional light intensity
    i_a = df['i_a'].to_numpy().reshape((-1,1))   # directional light intensity
    l = df[['l_x','l_y','l_z']].to_numpy()       # lighting direction
    n = df[['n_x','n_y','n_z']].to_numpy()       # plane surface normal
    costheta = (l*n).sum(axis=1, keepdims=True)  # cosine of angle between lighting direction and plane surface normal
    cubenum = df['cubenum']                      # number of cube file used
    
    # apply Lambertian or unlit rendering model
    if testLambertian:
        c = 0.822
        u_hat = c * srgb(m) * ( i_d * srgb(d) * costheta.clip(min=0) / np.pi + i_a * a ) / (2**e)
    else:
        u_hat = srgb(m)

    # choose range of knot points to optimize on this pass; points i1 to i2
    if passnum == 0:
        i1 = 2
        i2 = 31
    else:
        i1 = 2
        i2 = 17
    
    # constraint: each knot point is less than the next knot point
    nknot = (i2-i1)+1
    A1 = np.identity(nknot) + np.diag((nknot-1)*(-1,), 1)
    A1 = A1[:-1,:]
    lb1 = np.full((A1.shape[0],), -np.inf)
    ub1 = np.zeros((A1.shape[0],))
    
    # constraint: first knot point being varied is greater than its lower neighbour
    A2 = np.zeros((1, nknot))
    A2[0,0] = 1
    lb2 = np.array((tonemap[0].u_knot[i1-1],))
    ub2 = np.array((np.inf,))
    
    # constraint: last knot point being varied is less than its higher neighbour
    A3 = np.zeros((1, nknot))
    A3[0,-1] = 1
    lb3 = np.array((-np.inf,))
    if i2==31:
        ub3 = np.array((60,))
    else:
        ub3 = np.array((tonemap[0].u_knot[i2+1],))
    
    # combine constraints
    A = np.vstack((A1, A2, A3))
    lb = np.concatenate((lb1, lb2, lb3))
    ub = np.concatenate((ub1, ub2, ub3))
    cons = optimize.LinearConstraint(A=A, lb=lb, ub=ub)
    
    # define objective function that finds the sum-of-squares difference between
    # the post-processed coordinates v_k generated by render_random, and the
    # values v_k predicted by the current tonemapping function
    def errfn(param):
    
        # check that constraints are satisifed
        # (the tonemapping function throws an exception if they're not)
        x = A @ param
        if not ((lb < x) & (x < ub)).all():
            return np.inf
        
        # find prediction error
        err = 0
        for i in range(cuben):
            tonemap[i].u_knot[i1:i2+1] = param
            k = cubenum == i
            t_hat = tonemap[i].apply(u_hat[k,:])
            v_hat = srgbinv(t_hat)
            err += ((v[k,:]-v_hat)**2).sum()
        
        return err
    
    # find knot points that optimize prediction accuracy
    pinit = tonemap[0].u_knot[i1:i2+1]
    r = optimize.minimize(errfn, pinit, constraints=cons)
    print(r)
    
    # assign new points to tonemapping objects
    for t in tonemap:
        t.u_knot[i1:i2+1] = r.x

    # initialize plot for results
    fig = plt.figure(figsize=(13,5.5))
    ax1 = fig.add_subplot(1,2,1)
    ax2 = fig.add_subplot(1,2,2)
    
    # step through cube files
    handle1 = 3*[None,]
    handle2 = 3*[None,]
    err = []
    for i in range(len(cubelist)):
        
        # get data for this cube file, and apply post-processing
        k = cubenum == i
        t_hat = tonemap[i].apply(u_hat[k,:])
        v_hat = srgbinv(t_hat)
        vv = v[k,:]
        err.append(v_hat-vv)
        
        # plot predicted post-processed color coordinates v_k against actual v_k
        kk = np.random.randint(low=0, high=v_hat.shape[0], size=20)
        for j in range(3):
            handle1[i] = ax1.scatter(vv[kk,j], v_hat[kk,j], color='rgb'[i])
        
        # plot prediction error in v_k against actual v_k
        kk = np.random.randint(low=0, high=v_hat.shape[0], size=50)
        for j in range(3):
            handle2[i] = ax2.scatter(vv[kk,j], v_hat[kk,j] - vv[kk,j], color='rgb'[i])

    # find mean absolute error
    err = np.concatenate(err, axis=0)
    mae = np.median(abs(err))
    ax2.text(0.1, -0.018, f'error = {255 * mae:.2f} / 255', fontsize=12)

    # format left panel
    xylim = np.array([0,1.1])
    ax1.plot(xylim, xylim, 'k-')
    ax1.legend(handle1, ['linear', 'square', 'square root'], frameon=False, loc='upper left')
    ax1.set_xlabel('actual $v_k$', fontsize=18)
    ax1.set_ylabel('predicted $v_k$', fontsize=18)
    ax1.set_xlim(xylim)
    ax1.set_ylim(xylim)
    ax1.set_aspect(1)
    ax1.text(0.85,0.1,'(a)',fontsize=24)
    
    # format right panel
    xlim = np.array([0,1])
    ax2.legend(handle2, ['linear', 'square', 'square root'], frameon=False, loc='upper left')
    ax2.plot(xlim,(-1/255)*np.ones(2),'k-')
    ax2.plot(xlim,(1/255)*np.ones(2),'k-')
    ax2.set_xlabel('actual $v_k$', fontsize=18)
    ax2.set_ylabel('prediction error', fontsize=18)
    ax2.set_xlim(xlim)
    ax2.set_ylim((-0.02,0.02))
    ax2.set_aspect(1./ax2.get_data_ratio())
    ax2.text(0.85,-0.012,'(b)',fontsize=24)
    
    plt.savefig(f'figures/knots_from_model_pass{passnum+1}.pdf', bbox_inches='tight')
    plt.show()

# print knot points
print(np.array2string(tonemap[0].u_knot, formatter={'float' : lambda u : f'{u:.4g}'}, separator=', ', max_line_width=np.inf))
